{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d07ea4d5",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Api Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43f404ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importar librerias necesarias\n",
    "import kaggle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import itertools\n",
    "from PIL import Image\n",
    "from IPython.core import display as ICD\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20e7a508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importar libreria kaggle\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0573a938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llamar a la api key de kaggle instalada en el ordenador\n",
    "\n",
    "api = KaggleApi()\n",
    "api.authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8277f4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metodo para convertir en df los metadatos extraidos\n",
    "\n",
    "def convert_to_df(csv):\n",
    "    df = pd.DataFrame(data=csv)[0].str.split(',',expand=True)  \n",
    "    header = df.iloc[0]\n",
    "    df = df[1:]\n",
    "    df.columns = header\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23a3d48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temas de fundamentos de analisis de datos\n",
    "\n",
    "# temas = ['Data analysis', 'Data mining', 'Machine learning', 'Data extraction', 'Scrapy', 'data storage', \n",
    "          #'Data quality', 'data preprocessing', 'data cleaning', 'data manipulation', 'Missing data', 'Null Data', \n",
    "          #'outliers', 'data transformation', 'Dimensional reduction', 'Exploratory data analysis', 'Univariate data analysis', \n",
    "          #'Multivariate data analysis', 'Regression', 'Linear regression', 'Simple linear regression', 'Multiple Linear Regression', \n",
    "          #'Nonlinear regression', 'Data analysis', 'descriptive analysis', 'Frequency', 'Central tendency', 'Arithmetic mean', \n",
    "          #'statistical mode', 'Median', 'dispersion', 'range', 'variance', 'standard deviation', 'Correlation', \n",
    "          #'inferential analysis', 'Bayesian analysis', 'predictive analytics', 'prescriptive analytics']\n",
    "        \n",
    "temas = ['data science']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75fa8362",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = []\n",
    "for a in temas:\n",
    "    newTema = a.replace(' ', '-')\n",
    "    topics.append(newTema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a28eb8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data-science']\n"
     ]
    }
   ],
   "source": [
    "print(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "087a4833",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ref</th>\n",
       "      <th>title</th>\n",
       "      <th>size</th>\n",
       "      <th>lastUpdated</th>\n",
       "      <th>downloadCount</th>\n",
       "      <th>voteCount</th>\n",
       "      <th>usabilityRating</th>\n",
       "      <th>NaN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rashikrahmanpritom/heart-attack-analysis-predi...</td>\n",
       "      <td>Heart Attack Analysis &amp; Prediction Dataset</td>\n",
       "      <td>4KB</td>\n",
       "      <td>2021-03-22 11:40:59</td>\n",
       "      <td>92300</td>\n",
       "      <td>2632</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>erqizhou/students-data-analysis</td>\n",
       "      <td>Students Data Analysis</td>\n",
       "      <td>2KB</td>\n",
       "      <td>2022-07-20 03:54:13</td>\n",
       "      <td>2531</td>\n",
       "      <td>51</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0                                                ref  \\\n",
       "1                                                      \n",
       "2  rashikrahmanpritom/heart-attack-analysis-predi...   \n",
       "3                                                      \n",
       "4                    erqizhou/students-data-analysis   \n",
       "5                                                      \n",
       "\n",
       "0                                       title  size          lastUpdated  \\\n",
       "1                                        None  None                 None   \n",
       "2  Heart Attack Analysis & Prediction Dataset   4KB  2021-03-22 11:40:59   \n",
       "3                                        None  None                 None   \n",
       "4                      Students Data Analysis   2KB  2022-07-20 03:54:13   \n",
       "5                                        None  None                 None   \n",
       "\n",
       "0 downloadCount voteCount usabilityRating   NaN  \n",
       "1          None      None            None  None  \n",
       "2         92300      2632             1.0  None  \n",
       "3          None      None            None  None  \n",
       "4          2531        51             1.0  None  \n",
       "5          None      None            None  None  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# probando\n",
    "tema = 'Data-analysis'\n",
    "\n",
    "competitions_list_csv = !kaggle datasets list -s $tema --csv\n",
    "\n",
    "# print(competitions_list_csv)\n",
    "\n",
    "# print(type(competitions_list_csv))\n",
    "\n",
    "competitions_list_df = convert_to_df(competitions_list_csv)\n",
    "\n",
    "ICD.display(competitions_list_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "37989630",
   "metadata": {},
   "outputs": [],
   "source": [
    "ultimaColumna = competitions_list_df.iloc[:,-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "65007b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#competitions_list_df.columns.values[-3:]\n",
    "\n",
    "if ultimaColumna.columns.values[0] == None:\n",
    "    competitions_list_df = competitions_list_df.drop([None], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0998c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# competitions_list_df[columnas] = df[columnas].replace({'0m':''}, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c2b35616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ref</th>\n",
       "      <th>title</th>\n",
       "      <th>size</th>\n",
       "      <th>lastUpdated</th>\n",
       "      <th>downloadCount</th>\n",
       "      <th>voteCount</th>\n",
       "      <th>usabilityRating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rashikrahmanpritom/heart-attack-analysis-predi...</td>\n",
       "      <td>Heart Attack Analysis &amp; Prediction Dataset</td>\n",
       "      <td>4KB</td>\n",
       "      <td>2021-03-22 11:40:59</td>\n",
       "      <td>92235</td>\n",
       "      <td>2630</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>erqizhou/students-data-analysis</td>\n",
       "      <td>Students Data Analysis</td>\n",
       "      <td>2KB</td>\n",
       "      <td>2022-07-20 03:54:13</td>\n",
       "      <td>2530</td>\n",
       "      <td>51</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0                                                ref  \\\n",
       "1                                                      \n",
       "2  rashikrahmanpritom/heart-attack-analysis-predi...   \n",
       "3                                                      \n",
       "4                    erqizhou/students-data-analysis   \n",
       "5                                                      \n",
       "\n",
       "0                                       title  size          lastUpdated  \\\n",
       "1                                        None  None                 None   \n",
       "2  Heart Attack Analysis & Prediction Dataset   4KB  2021-03-22 11:40:59   \n",
       "3                                        None  None                 None   \n",
       "4                      Students Data Analysis   2KB  2022-07-20 03:54:13   \n",
       "5                                        None  None                 None   \n",
       "\n",
       "0 downloadCount voteCount usabilityRating  \n",
       "1          None      None            None  \n",
       "2         92235      2630             1.0  \n",
       "3          None      None            None  \n",
       "4          2530        51             1.0  \n",
       "5          None      None            None  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "competitions_list_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0927c8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "competitions_list_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "05f2bfbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ref</th>\n",
       "      <th>title</th>\n",
       "      <th>size</th>\n",
       "      <th>lastUpdated</th>\n",
       "      <th>downloadCount</th>\n",
       "      <th>voteCount</th>\n",
       "      <th>usabilityRating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rashikrahmanpritom/heart-attack-analysis-predi...</td>\n",
       "      <td>Heart Attack Analysis &amp; Prediction Dataset</td>\n",
       "      <td>4KB</td>\n",
       "      <td>2021-03-22 11:40:59</td>\n",
       "      <td>92235</td>\n",
       "      <td>2630</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>erqizhou/students-data-analysis</td>\n",
       "      <td>Students Data Analysis</td>\n",
       "      <td>2KB</td>\n",
       "      <td>2022-07-20 03:54:13</td>\n",
       "      <td>2530</td>\n",
       "      <td>51</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cosmos98/twitter-and-reddit-sentimental-analys...</td>\n",
       "      <td>Twitter and Reddit Sentimental analysis Dataset</td>\n",
       "      <td>10MB</td>\n",
       "      <td>2019-11-28 14:00:34</td>\n",
       "      <td>6596</td>\n",
       "      <td>94</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ariyoomotade/netflix-data-cleaning-analysis-an...</td>\n",
       "      <td>\"Netflix Data: Cleaning</td>\n",
       "      <td>Analysis and Visualization\"</td>\n",
       "      <td>270KB</td>\n",
       "      <td>2022-08-26 09:25:43</td>\n",
       "      <td>7457</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ahmtcnbs/datasets-for-appiori</td>\n",
       "      <td>Market Basket Analysis Data</td>\n",
       "      <td>8KB</td>\n",
       "      <td>2021-05-28 09:37:26</td>\n",
       "      <td>2870</td>\n",
       "      <td>43</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>columbine/imdb-dataset-sentiment-analysis-in-c...</td>\n",
       "      <td>IMDB dataset (Sentiment analysis) in CSV format</td>\n",
       "      <td>26MB</td>\n",
       "      <td>2019-11-28 15:44:05</td>\n",
       "      <td>13911</td>\n",
       "      <td>100</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>shashwatwork/dataco-smart-supply-chain-for-big...</td>\n",
       "      <td>DataCo SMART SUPPLY CHAIN FOR BIG DATA ANALYSIS</td>\n",
       "      <td>26MB</td>\n",
       "      <td>2019-12-05 06:54:29</td>\n",
       "      <td>10349</td>\n",
       "      <td>167</td>\n",
       "      <td>0.7647059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>davidbnn92/weather-data-for-covid19-data-analysis</td>\n",
       "      <td>Weather Data for COVID-19 Data Analysis</td>\n",
       "      <td>2MB</td>\n",
       "      <td>2020-04-12 17:14:26</td>\n",
       "      <td>2137</td>\n",
       "      <td>34</td>\n",
       "      <td>0.9705882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>pradeeshprabhakar/preprocessed-dataset-sentime...</td>\n",
       "      <td>Preprocessed Dataset Sentiment Analysis</td>\n",
       "      <td>117KB</td>\n",
       "      <td>2022-06-29 05:56:47</td>\n",
       "      <td>414</td>\n",
       "      <td>26</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>urstrulyvikas/lending-club-loan-data-analysis</td>\n",
       "      <td>Lending Club Loan Data Analysis</td>\n",
       "      <td>213KB</td>\n",
       "      <td>2021-05-24 03:38:11</td>\n",
       "      <td>1027</td>\n",
       "      <td>24</td>\n",
       "      <td>0.7058824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>dansbecker/aer-credit-card-data</td>\n",
       "      <td>\"Credit Card Data from book \"\"Econometric Anal...</td>\n",
       "      <td>24KB</td>\n",
       "      <td>2017-10-13 17:17:33</td>\n",
       "      <td>7432</td>\n",
       "      <td>59</td>\n",
       "      <td>0.7058824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>abderrahimalakouche/data-analysis-products-dat...</td>\n",
       "      <td>Products Data Analysis</td>\n",
       "      <td>89KB</td>\n",
       "      <td>2021-05-11 09:55:40</td>\n",
       "      <td>542</td>\n",
       "      <td>20</td>\n",
       "      <td>0.7647059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>jackdaoud/marketing-data</td>\n",
       "      <td>Marketing Analytics</td>\n",
       "      <td>643KB</td>\n",
       "      <td>2022-03-06 23:34:23</td>\n",
       "      <td>21774</td>\n",
       "      <td>394</td>\n",
       "      <td>0.9411765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>rashikrahmanpritom/groceries-dataset-for-marke...</td>\n",
       "      <td>Groceries dataset for Market Basket Analysis(MBA)</td>\n",
       "      <td>455KB</td>\n",
       "      <td>2021-04-03 04:01:37</td>\n",
       "      <td>2996</td>\n",
       "      <td>50</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>rutuspatel/retail-analysis-with-walmart-sales-...</td>\n",
       "      <td>RETAIL ANALYSIS WITH WALMART SALES DATA</td>\n",
       "      <td>122KB</td>\n",
       "      <td>2021-07-31 09:04:18</td>\n",
       "      <td>2468</td>\n",
       "      <td>28</td>\n",
       "      <td>0.8235294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>cities/titanic123</td>\n",
       "      <td>Titanic Dataset Analysis</td>\n",
       "      <td>22KB</td>\n",
       "      <td>2017-02-07 23:15:54</td>\n",
       "      <td>1817</td>\n",
       "      <td>33</td>\n",
       "      <td>0.5294118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>nikhilbhathi/data-scientist-salary-us-glassdoor</td>\n",
       "      <td>Data scientist salary</td>\n",
       "      <td>1023KB</td>\n",
       "      <td>2021-12-29 15:28:13</td>\n",
       "      <td>9337</td>\n",
       "      <td>163</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>shub99/sentiment-analysis-data</td>\n",
       "      <td>Sentiment Analysis Data</td>\n",
       "      <td>24KB</td>\n",
       "      <td>2021-08-04 07:23:11</td>\n",
       "      <td>567</td>\n",
       "      <td>13</td>\n",
       "      <td>0.88235295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>sasanj/human-activity-smart-devices</td>\n",
       "      <td>An Open Dataset for Human Activity Analysis</td>\n",
       "      <td>129MB</td>\n",
       "      <td>2017-09-01 07:30:59</td>\n",
       "      <td>4072</td>\n",
       "      <td>141</td>\n",
       "      <td>0.7058824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>ashfakyeafi/air-passenger-data-for-time-series...</td>\n",
       "      <td>Air Passenger Data for Time Series Analysis</td>\n",
       "      <td>764B</td>\n",
       "      <td>2021-08-06 14:46:29</td>\n",
       "      <td>350</td>\n",
       "      <td>39</td>\n",
       "      <td>0.7647059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0                                                 ref  \\\n",
       "2   rashikrahmanpritom/heart-attack-analysis-predi...   \n",
       "4                     erqizhou/students-data-analysis   \n",
       "6   cosmos98/twitter-and-reddit-sentimental-analys...   \n",
       "8   ariyoomotade/netflix-data-cleaning-analysis-an...   \n",
       "10                      ahmtcnbs/datasets-for-appiori   \n",
       "12  columbine/imdb-dataset-sentiment-analysis-in-c...   \n",
       "14  shashwatwork/dataco-smart-supply-chain-for-big...   \n",
       "16  davidbnn92/weather-data-for-covid19-data-analysis   \n",
       "18  pradeeshprabhakar/preprocessed-dataset-sentime...   \n",
       "20      urstrulyvikas/lending-club-loan-data-analysis   \n",
       "22                    dansbecker/aer-credit-card-data   \n",
       "24  abderrahimalakouche/data-analysis-products-dat...   \n",
       "26                           jackdaoud/marketing-data   \n",
       "28  rashikrahmanpritom/groceries-dataset-for-marke...   \n",
       "30  rutuspatel/retail-analysis-with-walmart-sales-...   \n",
       "32                                  cities/titanic123   \n",
       "34    nikhilbhathi/data-scientist-salary-us-glassdoor   \n",
       "36                     shub99/sentiment-analysis-data   \n",
       "38                sasanj/human-activity-smart-devices   \n",
       "40  ashfakyeafi/air-passenger-data-for-time-series...   \n",
       "\n",
       "0                                               title  \\\n",
       "2          Heart Attack Analysis & Prediction Dataset   \n",
       "4                              Students Data Analysis   \n",
       "6     Twitter and Reddit Sentimental analysis Dataset   \n",
       "8                             \"Netflix Data: Cleaning   \n",
       "10                        Market Basket Analysis Data   \n",
       "12    IMDB dataset (Sentiment analysis) in CSV format   \n",
       "14    DataCo SMART SUPPLY CHAIN FOR BIG DATA ANALYSIS   \n",
       "16            Weather Data for COVID-19 Data Analysis   \n",
       "18            Preprocessed Dataset Sentiment Analysis   \n",
       "20                    Lending Club Loan Data Analysis   \n",
       "22  \"Credit Card Data from book \"\"Econometric Anal...   \n",
       "24                             Products Data Analysis   \n",
       "26                                Marketing Analytics   \n",
       "28  Groceries dataset for Market Basket Analysis(MBA)   \n",
       "30            RETAIL ANALYSIS WITH WALMART SALES DATA   \n",
       "32                           Titanic Dataset Analysis   \n",
       "34                              Data scientist salary   \n",
       "36                            Sentiment Analysis Data   \n",
       "38        An Open Dataset for Human Activity Analysis   \n",
       "40        Air Passenger Data for Time Series Analysis   \n",
       "\n",
       "0                           size          lastUpdated        downloadCount  \\\n",
       "2                            4KB  2021-03-22 11:40:59                92235   \n",
       "4                            2KB  2022-07-20 03:54:13                 2530   \n",
       "6                           10MB  2019-11-28 14:00:34                 6596   \n",
       "8    Analysis and Visualization\"                270KB  2022-08-26 09:25:43   \n",
       "10                           8KB  2021-05-28 09:37:26                 2870   \n",
       "12                          26MB  2019-11-28 15:44:05                13911   \n",
       "14                          26MB  2019-12-05 06:54:29                10349   \n",
       "16                           2MB  2020-04-12 17:14:26                 2137   \n",
       "18                         117KB  2022-06-29 05:56:47                  414   \n",
       "20                         213KB  2021-05-24 03:38:11                 1027   \n",
       "22                          24KB  2017-10-13 17:17:33                 7432   \n",
       "24                          89KB  2021-05-11 09:55:40                  542   \n",
       "26                         643KB  2022-03-06 23:34:23                21774   \n",
       "28                         455KB  2021-04-03 04:01:37                 2996   \n",
       "30                         122KB  2021-07-31 09:04:18                 2468   \n",
       "32                          22KB  2017-02-07 23:15:54                 1817   \n",
       "34                        1023KB  2021-12-29 15:28:13                 9337   \n",
       "36                          24KB  2021-08-04 07:23:11                  567   \n",
       "38                         129MB  2017-09-01 07:30:59                 4072   \n",
       "40                          764B  2021-08-06 14:46:29                  350   \n",
       "\n",
       "0  voteCount usabilityRating  \n",
       "2       2630             1.0  \n",
       "4         51             1.0  \n",
       "6         94             1.0  \n",
       "8       7457             163  \n",
       "10        43             1.0  \n",
       "12       100             1.0  \n",
       "14       167       0.7647059  \n",
       "16        34       0.9705882  \n",
       "18        26             1.0  \n",
       "20        24       0.7058824  \n",
       "22        59       0.7058824  \n",
       "24        20       0.7647059  \n",
       "26       394       0.9411765  \n",
       "28        50             1.0  \n",
       "30        28       0.8235294  \n",
       "32        33       0.5294118  \n",
       "34       163             1.0  \n",
       "36        13      0.88235295  \n",
       "38       141       0.7058824  \n",
       "40        39       0.7647059  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "competitions_list_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3f0606e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "competitions_list_df.to_csv(\"competitions_list_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8bd0ac",
   "metadata": {},
   "source": [
    "## Extraer datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4a2d159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extraer competitions\n",
    "\n",
    "def getDataSets(topics):\n",
    "    \n",
    "    # extraccion de datos de la api, devuelve una lista\n",
    "    datasetsList = !kaggle datasets list -s $topics --all\n",
    "    \n",
    "    # condicional if para comprobar si me extrajo datos o no\n",
    "    if datasetsList[0] != \"No datasets found\":\n",
    "                \n",
    "        datasetsDF = convert_to_df(datasetsList) # convertir a df\n",
    "        \n",
    "        datasetsDF.insert(0,\"topic\",x,True)\n",
    "        datasetsDF.insert(1,\"set\",\"datasets\",True)\n",
    "        \n",
    "        ultimaColumna = datasetsDF.iloc[:,-1:] # sacar la ultima columna para verificar si está vacia o no\n",
    "        \n",
    "        # condicional if si la ultima columna esta vacia\n",
    "        if ultimaColumna.columns.values[0] == None:\n",
    "            \n",
    "            datasetsDF = datasetsDF.drop([None], axis=1) # eliminar columna vacia\n",
    "        \n",
    "        datasetsDF.dropna(inplace=True) # eliminar filas nulas\n",
    "        \n",
    "        ICD.display(datasetsDF.head()) # imprimir\n",
    "        \n",
    "        return(datasetsDF) # return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "846292ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ref,title,size,lastUpdated,downloadCount,voteCount,usabilityRating', '', 'akshaydattatraykhare/diabetes-dataset,Diabetes Dataset,9KB,2022-10-06 08:55:25,4770,152,1.0', '', 'vittoriogiatti/bigmacprice,Bigmac Prices,14KB,2022-10-19 21:11:14,964,27,1.0', '', 'whenamancodes/covid-19-coronavirus-pandemic-dataset,COVID -19 Coronavirus Pandemic Dataset,11KB,2022-09-30 04:05:11,3955,115,1.0', '', 'thedevastator/fast-food-restaurants-in-the-united-states,Fast Food Restaurants in the United States,4MB,2022-10-08 17:30:38,1369,39,1.0', '', 'whenamancodes/students-performance-in-exams,Students Performance in Exams,9KB,2022-09-14 15:14:54,7383,134,1.0', '', 'whenamancodes/student-performance,Student Performance,104KB,2022-10-07 05:14:47,5527,130,1.0', '', 'anushabellam/cars-cars-2,Cars_India_dataset,4KB,2022-10-12 06:34:20,796,27,1.0', '', 'iamsouravbanerjee/computer-games-dataset,Computer Games Dataset,29KB,2022-10-11 14:36:33,568,43,1.0', '', 'kathir1k/youtube-influencers-data,Youtube Channel and Influencer Analysis,196KB,2022-10-13 16:30:21,685,29,0.85294116', '', 'whenamancodes/flight-delay-prediction,Flight Delay Prediction,31MB,2022-10-07 05:26:20,1407,36,0.88235295', '', 'narayan63/netflix-popular-movies-dataset,Netflix popular movies dataset,1MB,2022-09-24 08:23:22,3617,57,0.9411765', '', 'evangower/premier-league-matches-19922022,Premier League Matches 1992-2022,78KB,2022-10-03 02:18:33,1344,47,1.0', '', 'whenamancodes/alcohol-effects-on-study,Alcohol Effects On Study,18KB,2022-09-15 03:21:04,4693,90,1.0', '', 'kathuman/housing,Housing,400KB,2022-09-29 10:21:23,829,26,1.0', '', 'whenamancodes/the-global-hunger-index,The Global Hunger Index,27KB,2022-09-13 18:18:01,1462,41,1.0', '', 'eliasturk/world-happiness-based-on-cpi-20152020,Happiness and Corruption 2015-2020,29KB,2022-10-11 22:35:03,851,31,1.0', '', 'jfreyberg/spotify-artist-feature-collaboration-network,Spotify Artist Feature Collaboration Network,15MB,2022-10-10 14:11:34,574,33,0.9117647', '', 'pantanjali/unemployment-dataset,Unemployment dataset,17KB,2022-09-08 08:26:10,6629,141,1.0', '', 'adnananam/spotify-artist-stats,Spotify Artist Stats,28KB,2022-09-22 03:22:44,1600,38,1.0', '', \"thedevastator/fuel-economy-data-how-efficient-are-today-s-cars,Fuel Economy Data: How Efficient Are Today's Cars?,1MB,2022-10-09 16:47:41,921,31,0.9411765\", '']\n"
     ]
    }
   ],
   "source": [
    "datasetsList = !kaggle datasets list --tags $topics --csv\n",
    "print(datasetsList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "952e1477",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>set</th>\n",
       "      <th>usage: kaggle [-h] [-v] {competitions</th>\n",
       "      <th>c</th>\n",
       "      <th>datasets</th>\n",
       "      <th>d</th>\n",
       "      <th>kernels</th>\n",
       "      <th>k</th>\n",
       "      <th>config} ...</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [topic, set, usage: kaggle [-h] [-v] {competitions, c, datasets, d, kernels, k, config} ...]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cont = 0\n",
    "\n",
    "for x in topics:\n",
    "    cont+=1\n",
    "    \n",
    "    dfDatasets = getDataSets(x)\n",
    "    \n",
    "    # ICD.display(dfDatasets.head()) # imprimir\n",
    "    \n",
    "    dfDatasets.to_csv(\"APIdata/datasets_\" + x + str(cont) + \".csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44fea28",
   "metadata": {},
   "source": [
    "## Extraer notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b82b691f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extraer competitions\n",
    "\n",
    "def getKernels(topics, count):\n",
    "    \n",
    "    # extraccion de datos de la api, devuelve una lista\n",
    "    kernelsList = !kaggle kernels list -s $topics --csv\n",
    "    \n",
    "    lista1 = kernelsList[0]\n",
    "    lista1 = lista1.split('-')[0]\n",
    "    # print(lista1)\n",
    "    \n",
    "    print(kernelsList)\n",
    "    \n",
    "    # condicional if para comprobar si me extrajo datos o no\n",
    "    if lista1 != \"500 \":\n",
    "                \n",
    "        kernelsDF = convert_to_df(kernelsList) # convertir a df\n",
    "        \n",
    "        kernelsDF.insert(0,\"topic\",x,True) # agregar columna con el tema\n",
    "        kernelsDF.insert(1,\"set\",\"kernels\",True) # agregar columnna con el tipo de metadato\n",
    "        \n",
    "        ultimaColumna = kernelsDF.iloc[:,-1:] # sacar la ultima columna para verificar si está vacia o no\n",
    "        \n",
    "        # condicional if si la ultima columna esta vacia\n",
    "        if ultimaColumna.columns.values[0] == None:\n",
    "            \n",
    "            kernelsDF = kernelsDF.drop([None], axis=1) # eliminar columna vacia\n",
    "        \n",
    "        kernelsDF.dropna(inplace=True) # eliminar filas nulas\n",
    "        \n",
    "        ICD.display(kernelsDF.head()) # imprimir\n",
    "        \n",
    "        kernelsDF.to_csv(\"APIdata/notebook_\" + x + str(count) + \".csv\")\n",
    "            \n",
    "        return(kernelsDF) # return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb03173f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "888007f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ref,title,author,lastRunTime,totalVotes', '', 'startupsci/titanic-data-science-solutions,Titanic Data Science Solutions,Manav Sehgal,2019-02-11 01:21:23,9263', '', 'ldfreeman3/a-data-science-framework-to-achieve-99-accuracy,A Data Science Framework: To Achieve 99% Accuracy,LD Freeman,2017-12-31 18:27:17,5221', '', 'helgejo/an-interactive-data-science-tutorial,An Interactive Data Science Tutorial,Helge Bjorland,2017-01-28 19:54:58,846', '', 'kanncaa1/data-sciencetutorial-for-beginners,Data ScienceTutorial for Beginners,DATAI,2020-05-19 00:29:44,6161', '', 'shivamb/data-science-glossary-on-kaggle,Data Science Glossary on Kaggle,Shivam Bansal,2018-12-10 09:47:14,2097', '', 'vbmokin/data-science-for-tabular-data-advanced-techniques,Data Science for tabular data: Advanced Techniques,Vitalii Mokin,2021-09-05 16:15:48,1119', '', 'rtatman/welcome-to-data-science-in-r,Welcome to Data Science in R,Rachael Tatman,2018-04-11 21:56:06,402', '', 'rtatman/welcome-to-data-science-in-r-workbook,Welcome to Data Science in R: Workbook,Rachael Tatman,2018-04-30 19:07:24,154', '', 'rounakbanik/data-science-faq,Data Science FAQ,Rounak Banik,2017-11-08 06:27:49,161', '', 'gzuidhof/full-preprocessing-tutorial,Full Preprocessing Tutorial,Guido Zuidhof,2017-02-24 06:16:38,2362', '', 'gpreda/2019-data-science-bowl-eda,2019 Data Science Bowl EDA,Gabriel Preda,2019-12-20 07:44:46,345', '', 'erikbruin/data-science-bowl-2019-eda-and-baseline,Data Science Bowl 2019 EDA and Baseline,Erik Bruin,2019-12-15 09:49:54,438', '', 'parulpandey/useful-python-libraries-for-data-science,Useful Python libraries for Data Science,Parul Pandey,2020-04-25 06:22:19,506', '', \"'charmap' codec can't encode character '\\\\U0001f6b8' in position 50: character maps to <undefined>\"]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>set</th>\n",
       "      <th>ref</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>lastRunTime</th>\n",
       "      <th>totalVotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data-science</td>\n",
       "      <td>kernels</td>\n",
       "      <td>startupsci/titanic-data-science-solutions</td>\n",
       "      <td>Titanic Data Science Solutions</td>\n",
       "      <td>Manav Sehgal</td>\n",
       "      <td>2019-02-11 01:21:23</td>\n",
       "      <td>9263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data-science</td>\n",
       "      <td>kernels</td>\n",
       "      <td>ldfreeman3/a-data-science-framework-to-achieve...</td>\n",
       "      <td>A Data Science Framework: To Achieve 99% Accuracy</td>\n",
       "      <td>LD Freeman</td>\n",
       "      <td>2017-12-31 18:27:17</td>\n",
       "      <td>5221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>data-science</td>\n",
       "      <td>kernels</td>\n",
       "      <td>helgejo/an-interactive-data-science-tutorial</td>\n",
       "      <td>An Interactive Data Science Tutorial</td>\n",
       "      <td>Helge Bjorland</td>\n",
       "      <td>2017-01-28 19:54:58</td>\n",
       "      <td>846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>data-science</td>\n",
       "      <td>kernels</td>\n",
       "      <td>kanncaa1/data-sciencetutorial-for-beginners</td>\n",
       "      <td>Data ScienceTutorial for Beginners</td>\n",
       "      <td>DATAI</td>\n",
       "      <td>2020-05-19 00:29:44</td>\n",
       "      <td>6161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>data-science</td>\n",
       "      <td>kernels</td>\n",
       "      <td>shivamb/data-science-glossary-on-kaggle</td>\n",
       "      <td>Data Science Glossary on Kaggle</td>\n",
       "      <td>Shivam Bansal</td>\n",
       "      <td>2018-12-10 09:47:14</td>\n",
       "      <td>2097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0          topic      set                                                ref  \\\n",
       "2   data-science  kernels          startupsci/titanic-data-science-solutions   \n",
       "4   data-science  kernels  ldfreeman3/a-data-science-framework-to-achieve...   \n",
       "6   data-science  kernels       helgejo/an-interactive-data-science-tutorial   \n",
       "8   data-science  kernels        kanncaa1/data-sciencetutorial-for-beginners   \n",
       "10  data-science  kernels            shivamb/data-science-glossary-on-kaggle   \n",
       "\n",
       "0                                               title          author  \\\n",
       "2                      Titanic Data Science Solutions    Manav Sehgal   \n",
       "4   A Data Science Framework: To Achieve 99% Accuracy      LD Freeman   \n",
       "6                An Interactive Data Science Tutorial  Helge Bjorland   \n",
       "8                  Data ScienceTutorial for Beginners           DATAI   \n",
       "10                    Data Science Glossary on Kaggle   Shivam Bansal   \n",
       "\n",
       "0           lastRunTime totalVotes  \n",
       "2   2019-02-11 01:21:23       9263  \n",
       "4   2017-12-31 18:27:17       5221  \n",
       "6   2017-01-28 19:54:58        846  \n",
       "8   2020-05-19 00:29:44       6161  \n",
       "10  2018-12-10 09:47:14       2097  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'APIdata/notebook_data-science0.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8660/123874201.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtopics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mdfKernels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetKernels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mcount\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8660/1375770935.py\u001b[0m in \u001b[0;36mgetKernels\u001b[1;34m(topics, count)\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mICD\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkernelsDF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# imprimir\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[0mkernelsDF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"APIdata/notebook_\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\".csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;32mreturn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkernelsDF\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# return\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3464\u001b[0m         )\n\u001b[0;32m   3465\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3466\u001b[1;33m         return DataFrameRenderer(formatter).to_csv(\n\u001b[0m\u001b[0;32m   3467\u001b[0m             \u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3468\u001b[0m             \u001b[0mline_terminator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mline_terminator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\formats\\format.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1103\u001b[0m             \u001b[0mformatter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         )\n\u001b[1;32m-> 1105\u001b[1;33m         \u001b[0mcsv_formatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1107\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcreated_buffer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    235\u001b[0m         \"\"\"\n\u001b[0;32m    236\u001b[0m         \u001b[1;31m# apply compression and byte/text conversion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 237\u001b[1;33m         with get_handle(\n\u001b[0m\u001b[0;32m    238\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    700\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'APIdata/notebook_data-science0.csv'"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "\n",
    "for x in topics:\n",
    "    \n",
    "    dfKernels = getKernels(x, count)\n",
    "    count+=1\n",
    "    \n",
    "    #dfKernels.to_csv(\"APIdata/notebook_\" + x + str(cont) + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f753de2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b4ba18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe08fd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f799ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# graphql khan academy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86e4c19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
